{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'spotify_mpc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.extend([\n",
    "    \"../../\",\n",
    "    \"../../execution\",\n",
    "    \"../../orchestration\",\n",
    "])\n",
    "\n",
    "import os\n",
    "from orchestration.spotify_mpc import orchestrate as orch\n",
    "from orchestration.submit import submit_job\n",
    "\n",
    "os.environ['PROJECT_NAME'] = PROJECT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Local\n",
    "os.environ['K8S_ENV'] = 'minikube'\n",
    "os.environ['DATA_DIR'] = '/'.join(os.getcwd().split(\"/\")[:-2] + ['data'])\n",
    "! ../../build_scripts/build_local.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_job(\n",
    "    orch.standardize_data(\n",
    "        input_directory=\"spotify_mpc/raw/spotify_million_playlist_dataset/data\",\n",
    "        output_directory=\"spotify_mpc/standardized\",\n",
    "        parts=list(range(100))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Remote\n",
    "import boto3\n",
    "os.environ['AWS_ACCOUNT_ID'] = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "os.environ['K8S_ENV'] = 'eks'\n",
    "os.environ['DATA_DIR'] = 's3://kube-transform-data-bucket'\n",
    "! ../../build_scripts/build_eks.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 cp ../../data/spotify_mpc/standardized s3://kube-transform-data-bucket/spotify_mpc/standardized --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for feature generation, and create challenge set to evaluate ourselves against\n",
    "submit_job(\n",
    "    orch.create_contest(\n",
    "        standardized_input_directory=\"spotify_mpc/standardized\",\n",
    "        train_parts=list(range(96)),\n",
    "        track_df_output_path=\"spotify_mpc/MPC/track_df.parquet\",\n",
    "        train_output_directory=\"spotify_mpc/MPC/train\",\n",
    "        test_part=99,\n",
    "        n_test_cases=5000,\n",
    "        challenge_set_output_path=\"spotify_mpc/MPC/challenge_set.parquet\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 30k challenge set playlists to train on\n",
    "for test_part in [96, 97, 98]:\n",
    "    submit_job(\n",
    "        orch.create_challenge_set(\n",
    "            standardized_input_directory=\"spotify_mpc/standardized\",\n",
    "            test_part=test_part,\n",
    "            track_df_path=\"spotify_mpc/MPC/track_df.parquet\",\n",
    "            n_test_cases=10000,\n",
    "            output_path=f\"spotify_mpc/MPC/challenge_set_training_{test_part}.parquet\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 cp ../../data/spotify_mpc/raw/spotify_million_playlist_dataset_challenge/challenge_set.json s3://kube-transform-data-bucket/spotify_mpc/raw/spotify_million_playlist_dataset_challenge/challenge_set.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a challenge set from the real test data.\n",
    "# We'll use this to create the file we submit to AI Crowd.\n",
    "submit_job(\n",
    "    orch.renumber_existing_challenge_set(\n",
    "        challenge_set_json_path=\"spotify_mpc/raw/spotify_million_playlist_dataset_challenge/challenge_set.json\",\n",
    "        track_df_path=\"spotify_mpc/MPC/track_df.parquet\",\n",
    "        output_path=f\"spotify_mpc/MPC/challenge_set_real.parquet\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_job(\n",
    "    orch.generate_co_dicts(\n",
    "        train_directory=\"spotify_mpc/MPC/train\",\n",
    "        challenge_df_paths=[f\"spotify_mpc/MPC/challenge_set{suffix}.parquet\" for suffix in [\"\", \"_training_96\", \"_training_97\", \"_training_98\", \"_real\"]],\n",
    "        partial_co_dict_output_directory=\"spotify_mpc/MPC/pco\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_job(\n",
    "    orch.reduce_co_partials(\n",
    "        partial_co_dict_directory=\"spotify_mpc/MPC/pco\",\n",
    "        co_dict_output_directory=\"spotify_mpc/MPC/co\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for suffix in [\"\", \"_training_96\", \"_training_97\", \"_training_98\", \"_real\"]:\n",
    "    submit_job(\n",
    "        orch.identify_artist_playlists(\n",
    "            challenge_df_path=f\"spotify_mpc/MPC/challenge_set{suffix}.parquet\",\n",
    "            track_df_path=\"spotify_mpc/MPC/track_df.parquet\",\n",
    "            output_path=f\"spotify_mpc/MPC/artist_pids{suffix}.json\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for suffix in [\"\", \"_training_96\", \"_training_97\", \"_training_98\", \"_real\"]:\n",
    "    submit_job(\n",
    "        orch.generate_generic_features_fcnn_mfe(\n",
    "            challenge_df_path=f\"spotify_mpc/MPC/challenge_set{suffix}.parquet\", #\n",
    "            track_df_path=\"spotify_mpc/MPC/track_df.parquet\",\n",
    "            artist_playlists_path=f\"spotify_mpc/MPC/artist_pids{suffix}.json\", #\n",
    "            co_dict_directory=\"spotify_mpc/MPC/co\",\n",
    "            output_directory=f\"spotify_mpc/MPC/generic_features_fcnn{suffix}\", #\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for suffix in [\"\", \"_training_96\", \"_training_97\", \"_training_98\", \"_real\"]:\n",
    "    submit_job(\n",
    "        orch.generate_track_features_fcnn_mfe(\n",
    "            challenge_df_path=f\"spotify_mpc/MPC/challenge_set{suffix}.parquet\", #\n",
    "            track_df_path=\"spotify_mpc/MPC/track_df.parquet\",\n",
    "            challenge_df_generic_features_directory=f\"spotify_mpc/MPC/generic_features_fcnn{suffix}\", #\n",
    "            co_dict_directory=\"spotify_mpc/MPC/co\",\n",
    "            output_directory=f\"spotify_mpc/MPC/samples_fcnn{suffix}\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Train your model with the colab notebook at this point.  Download the submission file and continue.\n",
    "\n",
    "You can train on:\n",
    "* samples_fcnn_training_96\n",
    "* samples_fcnn_training_97\n",
    "* samples_fcnn_training_98\n",
    "\n",
    "Then infer on:\n",
    "* samples_fcnn\n",
    "\n",
    "Then evaluate this result (like you did for the small contest) to see your results.\n",
    "\n",
    "Then infer on:\n",
    "* samples_fcnn_real\n",
    "\n",
    "And export that file into the format expected by AI Crowd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_job(\n",
    "    orch.evaluate_submission(\n",
    "        challenge_df_path=\"spotify_mpc/MPC/challenge_set.parquet\",\n",
    "        track_df_path=\"spotify_mpc/MPC/track_df.parquet\",\n",
    "        submission_directory=\"spotify_mpc/MPC/submission_fcnn\",\n",
    "        output_directory=\"spotify_mpc/MPC/evaluation_fcnn\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a submission file for AI Crowd ###\n",
    "\n",
    "from execution.generic import file_system_util as fs\n",
    "import pandas as pd\n",
    "\n",
    "TEAM_NAME = 'KUBE_TRANSFORM'\n",
    "TEAM_EMAIL = 'KUBE_TRANSFORM@example.com'\n",
    "\n",
    "output_filename = \"ai_crowd_submission.csv\"\n",
    "sub_df = fs.load_data('spotify_mpc/MPC/submission_fcnn_real.parquet')\n",
    "challenge_df = fs.load_data('spotify_mpc/MPC/challenge_set_real.parquet')\n",
    "track_df = fs.load_data('spotify_mpc/MPC/track_df.parquet')\n",
    "\n",
    "track_id_to_uri = track_df.track_uri.to_dict()\n",
    "\n",
    "challenge_df = challenge_df.set_index('pid', drop=False)\n",
    "challenge_df['suggested'] = sub_df['suggested']\n",
    "challenge_df['suggested_track_uris'] = challenge_df.suggested.apply(\n",
    "    lambda tracks: [track_id_to_uri[track] for track in tracks]\n",
    ")\n",
    "\n",
    "out = challenge_df[['pid', 'suggested_track_uris']].reset_index(drop=True)\n",
    "\n",
    "# Expand the list into separate columns\n",
    "df_expanded = pd.DataFrame(out['suggested_track_uris'].to_list()).fillna('')\n",
    "df_expanded.insert(0, 'pid', out['pid'])\n",
    "\n",
    "# Define the custom first line\n",
    "custom_line = f\"team_info,{TEAM_NAME},{TEAM_EMAIL}\"\n",
    "\n",
    "# Write to CSV\n",
    "csv_filename = output_filename\n",
    "with open(csv_filename, \"w\") as f:\n",
    "    f.write(custom_line + \"\\n\")  # Write the custom first line\n",
    "    df_expanded.to_csv(f, index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
